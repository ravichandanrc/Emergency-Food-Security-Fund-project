{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS5-qEObKoPe",
        "outputId": "9343fb31-ae69-40f2-9d54-c9df4cb862c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPQBCN2RK2XP"
      },
      "outputs": [],
      "source": [
        "#installing required modules\n",
        "!pip install pillow \n",
        "!pip install pytesseract\n",
        "!pip install easyocr\n",
        "!apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNtHGIedK6C3"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "from pytesseract import pytesseract, Output\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "from csv import writer\n",
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "037DYoQSM_qm"
      },
      "outputs": [],
      "source": [
        "# creates a file name with a padded number, specified prefix and extension\n",
        "def create_image_file_name(number, file_prefix=\"PDF-B-Image-\"):\n",
        "    file_ext = \".png\"\n",
        "    count = 1\n",
        "    temp = number\n",
        "    while temp >= 10:\n",
        "        count += 1\n",
        "        temp //= 10\n",
        "    padded_number = str(number).zfill(3) # Pad the number with zeros to a length of 3\n",
        "    file_name = f\"{file_prefix}{padded_number}{file_ext}\"\n",
        "    if os.path.exists(file_name):\n",
        "        raise FileExistsError(\"File already exists.\")\n",
        "    return file_name\n",
        "\n",
        "# calculates the differences between adjacent slice indices along a given axis\n",
        "def slice_differences(image, slice_indices, slice_axis):\n",
        "    result = []\n",
        "    size = len(slice_indices)\n",
        "\n",
        "    for i, val in enumerate(slice_indices):\n",
        "        if i == size - 1:\n",
        "            last_diff = image.shape[slice_axis] - val\n",
        "            result.append(last_diff)\n",
        "        else:\n",
        "            diff = slice_indices[i+1] - val\n",
        "            result.append(diff)\n",
        "    return result\n",
        "\n",
        "# PRE-PROCESSING\n",
        "# convert a given image to binary using OpenCV's thresholding functionality\n",
        "def convert_to_binary(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# convert a given image to absolute scale using OpenCV's convertScaleAbs function\n",
        "def convert_to_abs_scale(image):\n",
        "    image = cv2.convertScaleAbs(image)\n",
        "    return image\n",
        "\n",
        "# create an EasyOCR reader object for English language\n",
        "reader = easyocr.Reader(['en'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yk27iJ3NTKo"
      },
      "outputs": [],
      "source": [
        "def subset(file_name, file_number):\n",
        "\n",
        "    # define the path to the image files\n",
        "    # image_file = os.path.join(os.getcwd(), \"PDF B Images\", file_name)\n",
        "    image_file = \"/content/drive/MyDrive/1Extraction/PDF B - Sample Images/PDF-B-Image-072.png\"\n",
        "\n",
        "    # read the image file using cv2\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    # create an empty list to store the variable heights\n",
        "    var_heights = []\n",
        "\n",
        "    # pre-processing the image before data extraction\n",
        "    image = convert_to_binary(image)\n",
        "\n",
        "    # Define the region of interest for project number bounding boxes\n",
        "    x1, x2, y1, y2 = 30, 150, 100, 1600\n",
        "    proj_bboxes = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Define the markers for pages\n",
        "    odd_start_markers = [30, 155, 350, 720, 965, 1065, 1175, 1260, 1365, 1510, 1700]\n",
        "    even_start_markers = [35, 133, 236, 335, 495, 800, 1490, 1590]\n",
        "\n",
        "\n",
        "    #OCR data extraction\n",
        "    data = pytesseract.image_to_data(proj_bboxes, output_type=Output.DICT)\n",
        "\n",
        "    text_recognition_count = len(data[\"text\"])\n",
        "\n",
        "    cleaned_data = {\n",
        "        \"top\": [data[\"top\"][i] for i in range(text_recognition_count) if data[\"text\"][i] != \"\" and len(data[\"text\"][i]) > 2]\n",
        "    }\n",
        "\n",
        "    # Clean the output and extract relevant heights and widths\n",
        "    cleaned_data = {\"top\": []}\n",
        "    for idx in range(len(data[\"text\"])):\n",
        "        if data[\"text\"][idx] != \"\" and len(data[\"text\"][idx]) > 2:\n",
        "            cleaned_data[\"top\"].append(data[\"top\"][idx])\n",
        "    \n",
        "    # Calculate height differences between bounding boxes and cleaned data\n",
        "    height_slices = slice_differences(proj_bboxes, cleaned_data[\"top\"], 0)\n",
        "\n",
        "    # Calculate width differences in odd numbered cells\n",
        "    width_slices_odd = slice_differences(image, odd_start_markers, 1)\n",
        "\n",
        "    # Extract data from odd pages\n",
        "    odd_data = {}\n",
        "    for index, top in enumerate(cleaned_data[\"top\"]):\n",
        "        start_pos = top + 90\n",
        "        strip_image = image[start_pos:start_pos + height_slices[index], 0:image.shape[1]]\n",
        "        row_data = []\n",
        "        for col_index, left in enumerate(odd_start_markers):\n",
        "            cell = strip_image[0:strip_image.shape[1], left:left + width_slices_odd[col_index]]\n",
        "            cell_data_array = reader.readtext(cell, detail=0)  #detail=0 for extracting only the text without bounding box coordinates and conf\n",
        "            cell_string = \" \".join(cell_data_array).strip() or \"null\"\n",
        "            row_data.append(cell_string)\n",
        "        odd_data[index] = row_data\n",
        "\n",
        "\n",
        "    # Extract data from even pages\n",
        "    # new_even_image = os.path.join(os.getcwd(), \"PDF B Images\", create_image_file_name(number+1))\n",
        "    new_even_image = \"/content/drive/MyDrive/1Extraction/PDF B - Sample Images/PDF-B-Image-073.png\"\n",
        "    even_image = cv2.imread(new_even_image, 0)\n",
        "\n",
        "    # pre-processing the image before data extraction\n",
        "    # even_image = convert_to_binary(even_image)\n",
        "\n",
        "    width_slices_even = slice_differences(even_image, even_start_markers, 1)\n",
        "\n",
        "\n",
        "    # Extract data from even pages\n",
        "    even_data = {}\n",
        "    for index, top in enumerate(cleaned_data[\"top\"]):\n",
        "        start_pos = top + 140\n",
        "        strip_image = even_image[start_pos:start_pos + height_slices[index], 0:even_image.shape[1]]\n",
        "        row_data = []\n",
        "        for col_index, left in enumerate(even_start_markers):\n",
        "            cell = strip_image[0:strip_image.shape[1], left:left + width_slices_even[col_index]]\n",
        "            cell_data_array = reader.readtext(cell, detail=0)\n",
        "            cell_string = \" \".join(cell_data_array).strip() or \"null\"\n",
        "            row_data.append(cell_string)\n",
        "        even_data[index] = row_data + [f\"{file_number}-{file_number+1}\"]\n",
        "        \n",
        "\n",
        "    # # Combine odd and even page data\n",
        "    combined_data = {}\n",
        "    for index in range(len(odd_data)):\n",
        "        combined_data[index] = odd_data[index] + even_data[index]\n",
        "\n",
        "\n",
        "    # Return a list of data rows\n",
        "    return list(combined_data.values())\n",
        "\n",
        "# Writing the data into a CSV file\n",
        "start = 46\n",
        "for i in range(46,669,2):\n",
        "    page_data = subset(create_image_file_name(i), i)\n",
        "    print(\"Processing data for pages {} and {} is done.\".format(i, i+1))\n",
        "    \n",
        "    extracted_data = \"/content/drive/MyDrive/1Extraction/Output files in .csv/output -PDF B.csv\"\n",
        "    page_headers = [\"ProjectNumber\", \"Lead\", \"RecipientName\", \"RecipientType\", \"Indigenous\", \n",
        "                    \"Town_City_Community\", \"Province_Territory\", \"PostalCode\",\"ContactName\",\n",
        "                   \"ContactPhone\",\"ContactEmail\", \"Funding_Status\", \"Requested\", \"Approved\", \n",
        "                   \"Investment_Type\", \"Investment_Description\",\"Investment_Output\", \"Describe_Remaining_Need\",\n",
        "                    \"Additonal_Funding_Needed\", \"PageIndex\"]\n",
        "\n",
        "    if i == start:\n",
        "        with open(extracted_data, \"w+\", newline='') as init_file:\n",
        "            csv_writer = csv.writer(init_file) #csv header object\n",
        "            csv_writer.writerow(page_headers) #writing the header row\n",
        "\n",
        "    with open(extracted_data, 'a', newline='') as file:\n",
        "      csv_writer = csv.writer(file)\n",
        "      for row in page_data:\n",
        "        csv_writer.writerow(row) #writing the extracted data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
