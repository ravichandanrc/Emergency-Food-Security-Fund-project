{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPtbKeCpFkde",
        "outputId": "df8724de-2023-4ffd-8225-f58fe9cb1021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nceST-lmGXnE"
      },
      "outputs": [],
      "source": [
        "#installing required modules\n",
        "!pip install pillow \n",
        "!pip install pytesseract\n",
        "!pip install easyocr\n",
        "!apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaY0tByqKjzp"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "from pytesseract import pytesseract, Output\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "from csv import writer\n",
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNep3A0zLFEP"
      },
      "outputs": [],
      "source": [
        "# creates a file name with a padded number, specified prefix and extension\n",
        "def create_image_file_name(number, file_prefix=\"PDF-A-Image-\"):\n",
        "    file_ext = \".png\"\n",
        "    count = 1\n",
        "    temp = number\n",
        "    while temp >= 10:\n",
        "        count += 1\n",
        "        temp //= 10\n",
        "    padded_number = str(number).zfill(4) # Pad the number with zeros to a length of 4\n",
        "    file_name = f\"{file_prefix}{padded_number}{file_ext}\"\n",
        "    if os.path.exists(file_name):\n",
        "        raise FileExistsError(\"File already exists.\")\n",
        "    return file_name\n",
        "\n",
        "# calculates the differences between adjacent slice indices along a given axis\n",
        "def slice_differences(image, slice_indices, slice_axis):\n",
        "    result = []\n",
        "    size = len(slice_indices)\n",
        "\n",
        "    for i, val in enumerate(slice_indices):\n",
        "        if i == size - 1:\n",
        "            last_diff = image.shape[slice_axis] - val\n",
        "            result.append(last_diff)\n",
        "        else:\n",
        "            diff = slice_indices[i+1] - val\n",
        "            result.append(diff)\n",
        "    return result\n",
        "\n",
        "# PRE-PROCESSING\n",
        "# convert a given image to binary using OpenCV's thresholding functionality\n",
        "def convert_to_binary(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# convert a given image to absolute scale using OpenCV'sconvertScaleAbs function\n",
        "def convert_to_abs_scale(image):\n",
        "    image = cv2.convertScaleAbs(image)\n",
        "    return image\n",
        "\n",
        "# create an EasyOCR reader object for English language\n",
        "reader = easyocr.Reader(['en'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID_0S3euTuO_"
      },
      "outputs": [],
      "source": [
        "def subset_1(file_name, file_number):\n",
        "\n",
        "    # define the path to the image files\n",
        "    # image_file = os.path.join(os.getcwd(), \"PDF A Images\", file_name)\n",
        "    image_file = \"/content/drive/MyDrive/1Extraction/PDF A - Sample Images/PDF A-Image-0011.png\"\n",
        "\n",
        "    # read the image file using cv2\n",
        "    image = cv2.imread(image_file) #reference: https://www.geeksforgeeks.org/python-opencv-cv2-imread-method/ \n",
        "\n",
        "    # create an empty list to store the variable heights\n",
        "    var_heights = []\n",
        "\n",
        "    # pre-processing the image before data extraction\n",
        "    # image = convert_to_binary(image)\n",
        "\n",
        "    # Define the region of interest for project number bounding boxes\n",
        "    x1, x2, y1, y2 = 30, 150, 180, 1600\n",
        "    proj_bboxes = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Define the region of interest of image for data extraction\n",
        "    x1, x2, y1, y2 = 30, 1200, 180, 1600\n",
        "    image_roi = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Define the markers for pages\n",
        "    odd_start_markers = [10, 170, 324, 485, 695, 820, 925, 1090]\n",
        "    even_start_markers = [51, 195, 395, 515, 690, 870, 1000, 1195, 1330, 1480]\n",
        "\n",
        "\n",
        "    #OCR data extraction\n",
        "    data = pytesseract.image_to_data(proj_bboxes, output_type=Output.DICT) #reference: https://stackoverflow.com/questions/20831612/getting-the-bounding-box-of-the-recognized-words-using-python-tesseract\n",
        "\n",
        "    # Clean the output and extract relevant heights and widths\n",
        "    cleaned_data = {\"top\": []}\n",
        "    for idx in range(len(data[\"text\"])):\n",
        "        if data[\"text\"][idx] != \"\" and len(data[\"text\"][idx]) > 2:\n",
        "            cleaned_data[\"top\"].append(data[\"top\"][idx])\n",
        "    \n",
        "    # Calculate height differences between bounding boxes and cleaned data\n",
        "    height_slices = slice_differences(proj_bboxes, cleaned_data[\"top\"], 0)\n",
        "\n",
        "    # Calculate width differences in odd numbered page cells\n",
        "    width_slices_odd = slice_differences(image_roi, odd_start_markers, 1)\n",
        "\n",
        "    # Extract data from odd pages\n",
        "    odd_data = {}\n",
        "    for index, top in enumerate(cleaned_data[\"top\"]):\n",
        "        start_pos = top - 10\n",
        "        strip_image = image_roi[start_pos:start_pos + height_slices[index], 0:image_roi.shape[1]]\n",
        "        row_data = []\n",
        "        for col_index, left in enumerate(odd_start_markers):\n",
        "            cell = strip_image[0:strip_image.shape[1], left:left + width_slices_odd[col_index]]\n",
        "            cell_data_array = reader.readtext(cell, detail=0) #detail=0 for extracting only the text without bounding box coordinates and conf\n",
        "            cell_string = \" \".join(cell_data_array).strip() or \"null\"\n",
        "            row_data.append(cell_string)\n",
        "        odd_data[index] = row_data + [\"null\"] * 5\n",
        "\n",
        "\n",
        "    # Extract data from even pages\n",
        "    # new_even_image = os.path.join(os.getcwd(), \"PDF A Images\", create_image_file_name(number+1))\n",
        "    new_even_image = \"/content/drive/MyDrive/1Extraction/PDF A - Sample Images/PDF A-Image-0012.png\"\n",
        "    even_image = cv2.imread(new_even_image, 0)\n",
        "\n",
        "    # Calculate width differences in even numbered page cells\n",
        "    width_slices_even = slice_differences(even_image, even_start_markers, 1)\n",
        "\n",
        "\n",
        "    # Extract data from even pages\n",
        "    even_data = {}\n",
        "    for index, top in enumerate(cleaned_data[\"top\"]):\n",
        "        start_pos = top + 140\n",
        "        strip_image = even_image[start_pos:start_pos + height_slices[index], 0:even_image.shape[1]]\n",
        "        row_data = []\n",
        "        for col_index, left in enumerate(even_start_markers):\n",
        "            cell = strip_image[0:strip_image.shape[1], left:left + width_slices_even[col_index]]\n",
        "            cell_data_array = reader.readtext(cell, detail=0)\n",
        "            cell_string = \" \".join(cell_data_array).strip() or \"null\"\n",
        "            row_data.append(cell_string)\n",
        "        even_data[index] = row_data + [f\"{file_number}-{file_number+1}\"]\n",
        "        \n",
        "\n",
        "    # # Combine odd and even page data\n",
        "    combined_data = {}\n",
        "    for index in range(len(odd_data)):\n",
        "        combined_data[index] = odd_data[index] + even_data[index]\n",
        "\n",
        "\n",
        "    # Return a list of data rows\n",
        "    return list(combined_data.values())\n",
        "\n",
        "# Writing the data into a CSV file\n",
        "start = 1\n",
        "for i in range(1,1544,2):\n",
        "    page_data = subset_1(create_image_file_name(i), i)\n",
        "    print(\"Processing data for pages {} and {} is done.\".format(i, i+1))\n",
        "    \n",
        "    extracted_data = \"/content/drive/MyDrive/1Extraction/Output files in .csv/output 1-PDF A.csv\"\n",
        "    page_headers = [\"ProjectNumber\", \"Lead\", \"RecipientName\", \"RecipientType\", \"Indigenous\", \n",
        "                    \"VulnerableGroups\", \"Town_City_Community\", \"Province_Territory\", \"PostalCode\",\"ContactName\",\n",
        "                   \"ContactPhone\",\"ContactEmail\", \"Status\", \"TotalRequested\", \"ApprovedFunding_NonAAFC\", \n",
        "                   \"ApprovedFunding_AAFC\", \"TotalApproved_Funding\",\"DataApproved_Rejected\", \"Date_Paid\", \"Type_of_Investment\", \"Description\",\n",
        "                   \"NumberPeopleServed\", \"Notes\", \"PageIndex\"]\n",
        "\n",
        "    if i == start:\n",
        "        with open(extracted_data, \"w+\", newline='') as init_file:\n",
        "            csv_writer = csv.writer(init_file) #csv header object\n",
        "            csv_writer.writerow(page_headers) #writing the header row\n",
        "\n",
        "    with open(extracted_data, 'a', newline='') as file:\n",
        "      csv_writer = csv.writer(file)\n",
        "      for row in page_data:\n",
        "        csv_writer.writerow(row) #writing the extracted data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5fk4abcGCbr"
      },
      "outputs": [],
      "source": [
        "def subset_2(file_name, file_number):\n",
        "   \n",
        "    # image_1_path = os.path.join(os.getcwd(), \"PDF A Images\", file_name)\n",
        "    image_1_path = \"/content/drive/MyDrive/1Extraction/PDF A - Sample Images/PDF A-Image-1605.png\"\n",
        "    image = cv2.imread(image_1_path, 0) \n",
        "\n",
        "    # pre-processing the image before data extraction\n",
        "    # image = convert_to_abs_scale(image)\n",
        "    proj_bboxes = image[150:1600, 50:300]\n",
        "\n",
        "    #OCR data extraction\n",
        "    data = pytesseract.image_to_data(proj_bboxes, output_type=Output.DICT)\n",
        "\n",
        "    # Define the markers for each page\n",
        "    widths_set_page1 = [50, 320, 535, 850, 1150, 1360, 1650, 1900]\n",
        "    widths_set_page2 = [60, 268, 509, 806, 1116, 1300, 1481, 1765]\n",
        "    widths_set_page3 = [150, 425, 630, 750, 1080, 1300, 1580]\n",
        "    \n",
        "    text_recognition_count = len(data[\"text\"])\n",
        "\n",
        "    cleaned_data = {\n",
        "        \"top\": [data[\"top\"][i] for i in range(text_recognition_count) if data[\"text\"][i] != \"\" and len(data[\"text\"][i]) > 2]\n",
        "    }\n",
        "\n",
        "    # Calculates the height differences between bounding boxes and cleaned data\n",
        "    height_slices = slice_differences(proj_bboxes , cleaned_data[\"top\"], 0)\n",
        "\n",
        "    # Calculates the width differences between the image and width markers\n",
        "    width_differences = slice_differences(image, widths_set_page1, 1)\n",
        "\n",
        "    temp_data = {}\n",
        "\n",
        "    temp_array = []\n",
        "\n",
        "    for i in range(len(cleaned_data[\"top\"])):\n",
        "        temp_start = cleaned_data[\"top\"][i] + 140\n",
        "        temp_strip_image = image[ temp_start : temp_start + height_slices[i], 0:image.shape[1]]\n",
        "        temp_array = []\n",
        "        for j in range(len(width_differences)):\n",
        "            cell = temp_strip_image[0:temp_strip_image.shape[1] , widths_set_page1[j] : widths_set_page1[j] + width_differences[j]]\n",
        "            cell_data_array = reader.readtext(cell, detail = 0)\n",
        "            cell_string = \" \".join(cell_data_array)\n",
        "            if cell_string == \"\":\n",
        "                cell_string = \"null\"\n",
        "            temp_array.append(cell_string)\n",
        "        temp_data[i] = temp_array\n",
        "\n",
        "\n",
        "    # Extract data from second page\n",
        "    # image_2_path = os.path.join(os.getcwd(), \"PDF A Images\", create_image_file_name(number+1))\n",
        "    image_2_path = \"/content/drive/MyDrive/1Extraction/PDF A - Sample Images/PDF A-Image-1606.png\"\n",
        "    image_2 = cv2.imread(image_2_path, 0)\n",
        "    # image_2 = convert_to_abs_scale(image_2)\n",
        "\n",
        "    width_differences = slice_differences(image_2, widths_set_page2, 1)\n",
        "\n",
        "    temp_array = []\n",
        "\n",
        "    for i in range(len(cleaned_data[\"top\"])):\n",
        "        temp_start = cleaned_data[\"top\"][i] + 140\n",
        "        temp_strip_image = image_2[ temp_start : temp_start + height_slices[i], 0:image_2.shape[1]]\n",
        "        temp_array = []\n",
        "        for j in range(len(width_differences)):\n",
        "            cell = temp_strip_image[0:temp_strip_image.shape[1] , widths_set_page2[j] : widths_set_page2[j] + width_differences[j]]\n",
        "            cell_data_array = reader.readtext(cell, detail = 0)\n",
        "            cell_string = \" \".join(cell_data_array)\n",
        "            if cell_string == \"\":\n",
        "                cell_string = \"null\"\n",
        "            temp_array.append(cell_string)\n",
        "        \n",
        "        temp_data[i] += temp_array\n",
        "\n",
        "    # Extract data from third page\n",
        "    # image_3_path = os.path.join(os.getcwd(), \"PDF A Images\", create_image_file_name(number+2))\n",
        "    image_3_path = \"/content/drive/MyDrive/1Extraction/PDF A - Sample Images/PDF A-Image-1607.png\"\n",
        "    image_3 = cv2.imread(image_3_path, 0)\n",
        "    # image_3 = convert_to_abs_scale(image_3)\n",
        "\n",
        "    width_differences = slice_differences(image_3, widths_set_page3, 1)\n",
        "\n",
        "    for i in range(len(cleaned_data[\"top\"])):\n",
        "        temp_start = cleaned_data[\"top\"][i] + 140\n",
        "        temp_strip_image = image_3[ temp_start : temp_start + height_slices[i], 0:image_3.shape[1]]\n",
        "        temp_array = []\n",
        "        for j in range(len(width_differences)):\n",
        "            cell = temp_strip_image[0:temp_strip_image.shape[1] , widths_set_page3[j] : widths_set_page3[j] + width_differences[j]]\n",
        "            cell_data_array = reader.readtext(cell, detail = 0)\n",
        "            cell_string = \" \".join(cell_data_array)\n",
        "            if cell_string == \"\":\n",
        "                cell_string = \"null\"\n",
        "            temp_array.append(cell_string)\n",
        "\n",
        "    # combining the data from three pages into one\n",
        "        temp_data[i] += temp_array + [f\"{file_number}-{file_number+1}-{file_number+2}\"]\n",
        "    return temp_data.values()\n",
        "\n",
        "# Writing the data into a CSV file\n",
        "start = 1544\n",
        "for i in range(1544,2354,3):\n",
        "    page_data = subset_2(create_image_file_name(i), i)\n",
        "    print(\"Processing data for pages {}, {} and {} is done.\".format(i, i+1, i+2))\n",
        "    \n",
        "    extracted_data = \"/content/drive/MyDrive/1Extraction/Output files in .csv/output 2-PDF A.csv\"\n",
        "    page_headers = [\"ProjectNumber\", \"Lead\", \"RecipientName\", \"RecipientType\", \"Indigenous\", \n",
        "                    \"VulnerableGroups\", \"Town_City_Community\", \"Province_Territory\", \"PostalCode\",\"ContactName\",\n",
        "                   \"ContactPhone\",\"ContactEmail\", \"Status\", \"TotalRequested\", \"ApprovedFunding_NonAAFC\", \n",
        "                   \"ApprovedFunding_AAFC\", \"TotalApproved_Funding\",\"DataApproved_Rejected\", \"Date_Paid\", \"Type_of_Investment\", \"Description\",\n",
        "                   \"NumberPeopleServed\", \"Notes\", \"PageIndex\"]\n",
        "\n",
        "    if i == start:\n",
        "        with open(extracted_data, \"w+\", newline='') as init_file:\n",
        "            csv_writer = csv.writer(init_file) #csv header object\n",
        "            csv_writer.writerow(page_headers) #writing the header row\n",
        "\n",
        "    with open(extracted_data, 'a', newline='') as file:\n",
        "      csv_writer = csv.writer(file)\n",
        "      for row in page_data:\n",
        "        csv_writer.writerow(row) #writing the extracted data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
